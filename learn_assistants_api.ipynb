{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning material: https://github.com/openai/openai-cookbook/blob/main/examples/Assistants_API_overview_python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# pretty printing helper\n",
    "import json\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
    ")\n",
    "show_json(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask our Assistant to explain the result a bit further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message to append to our thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Could you explain this to me?\"\n",
    ")\n",
    "\n",
    "# Execute our run\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# Wait for completion\n",
    "wait_on_run(run, thread)\n",
    "\n",
    "# Retrieve all the messages added after our last user message\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, order=\"asc\", after=message.id\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=user_message\n",
    "    )\n",
    "    return client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "def get_response(thread):\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all of these API calls are asynchronous operations; this means we actually get async behavior in our code without the use of async libraries! (e.g. asyncio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_and_run(user_input):\n",
    "    thread = client.beta.threads.create()\n",
    "    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)\n",
    "    return thread, run\n",
    "\n",
    "\n",
    "# Emulating concurrent user requests\n",
    "thread1, run1 = create_thread_and_run(\n",
    "    \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "thread2, run2 = create_thread_and_run(\"Could you explain linear algebra to me?\")\n",
    "thread3, run3 = create_thread_and_run(\"I don't like math. What can I do?\")\n",
    "\n",
    "# Now all Runs are executing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Pretty printing helper\n",
    "def pretty_print(messages):\n",
    "    print(\"# Messages\")\n",
    "    for m in messages:\n",
    "        print(f\"{m.role}: {m.content[0].text.value}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Waiting in a loop\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "\n",
    "# Wait for Run 1\n",
    "run1 = wait_on_run(run1, thread1)\n",
    "pretty_print(get_response(thread1))\n",
    "\n",
    "# Wait for Run 2\n",
    "run2 = wait_on_run(run2, thread2)\n",
    "pretty_print(get_response(thread2))\n",
    "\n",
    "# Wait for Run 3\n",
    "run3 = wait_on_run(run3, thread3)\n",
    "pretty_print(get_response(thread3))\n",
    "\n",
    "# Thank our assistant on Thread 3 :)\n",
    "run4 = submit_message(MATH_ASSISTANT_ID, thread3, \"Thank you!\")\n",
    "run4 = wait_on_run(run4, thread3)\n",
    "pretty_print(get_response(thread3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we use Code Interpreter in Assistant API to solve the same problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Generate the first 20 fibbonaci numbers with code.\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some use cases this may be enough â€“ however, if we want more details on what precisely an Assistant is doing we can take a look at a Run's Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id, run_id=run.id, order=\"asc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in run_steps.data:\n",
    "    step_details = step.step_details\n",
    "    print(json.dumps(show_json(step_details), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_ASSISTANT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\n",
    "        \"data/cities_for_map.csv\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")\n",
    "# Update Assistant\n",
    "# assistant = client.beta.assistants.update(\n",
    "#     MATH_ASSISTANT_ID,\n",
    "#     tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "#     file_ids=[file.id],\n",
    "# )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are professional frontend data visualization developer. Please generate code that answers users questions on data\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    file_ids=[file.id],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Can you describe the data?\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can the assistant handle two csv files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data = client.files.create(\n",
    "    file=open(\n",
    "        \"data/cities_for_map.csv\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")\n",
    "\n",
    "city_data_catalogue = client.files.create(\n",
    "    file=open(\n",
    "        \"data/catalogue.csv\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_IlfxlF2eIwYoQQ4PZE3U5tBw',\n",
       " 'created_at': 1713299059,\n",
       " 'description': None,\n",
       " 'file_ids': ['file-rOsPKMwi3BSKNFOVeO1Gnpcq',\n",
       "  'file-swrBVR6MDG9QDWZsJ0zIAsaK'],\n",
       " 'instructions': 'You are professional data visualization developer. Please generate code that answers users questions on data',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'name': 'Data Visualization Developer',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}, {'type': 'retrieval'}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'response_format': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    name=\"Data Visualization Developer\",\n",
    "    instructions=\"You are professional data visualization developer. Please generate code that answers users questions on data\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    assistant_id='asst_IlfxlF2eIwYoQQ4PZE3U5tBw',\n",
    "    file_ids=[city_data.id,city_data_catalogue.id],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"You are given two data files. \\\n",
    "        cities_for_map.csv is the data that describe emissoins of cities from different kinds of wastes. catalogue.csv is the file of data catalogue,\\\n",
    "            which describes the column headers of the cities_for_map.csv. Please generate \\\n",
    "        code that can make an interactive map using 2022 emissions data. Each bubble on the map represents one city. The size of  \\\n",
    "        the bubble is proportional to the total emissions for the city. When users click on the ciy, it will\\\n",
    "             show the emissions for each type of waste as a pie chart.\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id, run_id=run.id, order=\"asc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in run_steps.data:\n",
    "    step_details = step.step_details\n",
    "    print(json.dumps(show_json(step_details), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = submit_message(assistant.id, thread, \"Please print code only\")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
