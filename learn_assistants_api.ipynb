{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning material: https://github.com/openai/openai-cookbook/blob/main/examples/Assistants_API_overview_python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# pretty printing helper\n",
    "import json\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       " 'created_at': 1713281425,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'response_format': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU',\n",
       " 'created_at': 1713281430,\n",
       " 'metadata': {},\n",
       " 'object': 'thread'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_6GBvx7xAhB0IcX9gRMRBAbga',\n",
       " 'assistant_id': None,\n",
       " 'completed_at': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1713281432,\n",
       " 'file_ids': [],\n",
       " 'incomplete_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'status': None,\n",
       " 'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
    ")\n",
    "show_json(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_yY42hBbv9qXwg8owYrNEChFE',\n",
       " 'assistant_id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1713281435,\n",
       " 'expires_at': 1713282035,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU',\n",
       " 'tools': [],\n",
       " 'usage': None,\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'incomplete_details': None,\n",
       " 'response_format': 'auto',\n",
       " 'tool_choice': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_yY42hBbv9qXwg8owYrNEChFE',\n",
       " 'assistant_id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1713281436,\n",
       " 'created_at': 1713281435,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1713281435,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU',\n",
       " 'tools': [],\n",
       " 'usage': {'completion_tokens': 12, 'prompt_tokens': 48, 'total_tokens': 60},\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'truncation_strategy': {'type': 'auto', 'last_messages': None},\n",
       " 'incomplete_details': None,\n",
       " 'response_format': 'auto',\n",
       " 'tool_choice': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_GCXFXyuiNvrkj3aeA8ojMwLd',\n",
       "   'assistant_id': None,\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1712875616,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_oBBkudNMbVsXgpGIpIlgNIO3'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_GCXFXyuiNvrkj3aeA8ojMwLd',\n",
       " 'last_id': 'msg_GCXFXyuiNvrkj3aeA8ojMwLd',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_uf2C8mVHzf4Nb8M7OM2eKigN',\n",
       "   'assistant_id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'Yes, the solution is x = 1.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1713281436,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_yY42hBbv9qXwg8owYrNEChFE',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU'},\n",
       "  {'id': 'msg_6GBvx7xAhB0IcX9gRMRBAbga',\n",
       "   'assistant_id': None,\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1713281432,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_uf2C8mVHzf4Nb8M7OM2eKigN',\n",
       " 'last_id': 'msg_6GBvx7xAhB0IcX9gRMRBAbga',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask our Assistant to explain the result a bit further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_rgB5Xhp4j7L90lklI7jciYIB',\n",
       "   'assistant_id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'Sure, you can solve for x by subtracting 11 from both sides and then dividing by 3 to isolate x.'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1713282292,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_XZqYiYRLmqyxI7XHZbZNVvaY',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_UBNuUjvlzX5b4WtA2GCmHxuU'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_rgB5Xhp4j7L90lklI7jciYIB',\n",
       " 'last_id': 'msg_rgB5Xhp4j7L90lklI7jciYIB',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a message to append to our thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Could you explain this to me?\"\n",
    ")\n",
    "\n",
    "# Execute our run\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# Wait for completion\n",
    "wait_on_run(run, thread)\n",
    "\n",
    "# Retrieve all the messages added after our last user message\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, order=\"asc\", after=message.id\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "MATH_ASSISTANT_ID = assistant.id  # or a hard-coded ID like \"asst-...\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=user_message\n",
    "    )\n",
    "    return client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "def get_response(thread):\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all of these API calls are asynchronous operations; this means we actually get async behavior in our code without the use of async libraries! (e.g. asyncio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_and_run(user_input):\n",
    "    thread = client.beta.threads.create()\n",
    "    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)\n",
    "    return thread, run\n",
    "\n",
    "\n",
    "# Emulating concurrent user requests\n",
    "thread1, run1 = create_thread_and_run(\n",
    "    \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "thread2, run2 = create_thread_and_run(\"Could you explain linear algebra to me?\")\n",
    "thread3, run3 = create_thread_and_run(\"I don't like math. What can I do?\")\n",
    "\n",
    "# Now all Runs are executing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: I need to solve the equation `3x + 11 = 14`. Can you help me?\n",
      "assistant: Sure, the solution for the equation `3x + 11 = 14` is `x = 1`.\n",
      "\n",
      "# Messages\n",
      "user: Could you explain linear algebra to me?\n",
      "assistant: Linear algebra is a branch of mathematics that deals with equations representing straight lines or linear relationships between variables, often involving matrices and vectors.\n",
      "\n",
      "# Messages\n",
      "user: I don't like math. What can I do?\n",
      "assistant: Try to approach math with a positive attitude and practice regularly to improve your skills.\n",
      "\n",
      "# Messages\n",
      "user: I don't like math. What can I do?\n",
      "assistant: Try to approach math with a positive attitude and practice regularly to improve your skills.\n",
      "user: Thank you!\n",
      "assistant: You're welcome! If you have any more questions, feel free to ask.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Pretty printing helper\n",
    "def pretty_print(messages):\n",
    "    print(\"# Messages\")\n",
    "    for m in messages:\n",
    "        print(f\"{m.role}: {m.content[0].text.value}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Waiting in a loop\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "\n",
    "# Wait for Run 1\n",
    "run1 = wait_on_run(run1, thread1)\n",
    "pretty_print(get_response(thread1))\n",
    "\n",
    "# Wait for Run 2\n",
    "run2 = wait_on_run(run2, thread2)\n",
    "pretty_print(get_response(thread2))\n",
    "\n",
    "# Wait for Run 3\n",
    "run3 = wait_on_run(run3, thread3)\n",
    "pretty_print(get_response(thread3))\n",
    "\n",
    "# Thank our assistant on Thread 3 :)\n",
    "run4 = submit_message(MATH_ASSISTANT_ID, thread3, \"Thank you!\")\n",
    "run4 = wait_on_run(run4, thread3)\n",
    "pretty_print(get_response(thread3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we use Code Interpreter in Assistant API to solve the same problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_9AoXVWBxHzWGAb6bYJqyI4tK',\n",
       " 'created_at': 1713281425,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'response_format': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: Generate the first 20 fibbonaci numbers with code.\n",
      "assistant: The first 20 Fibonacci numbers are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Generate the first 20 fibbonaci numbers with code.\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some use cases this may be enough â€“ however, if we want more details on what precisely an Assistant is doing we can take a look at a Run's Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id, run_id=run.id, order=\"asc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_calls': [{'id': 'call_2QtMnzzgMLwiGY48hgxtCr9h',\n",
       "   'code_interpreter': {'input': 'def fibonacci(n):\\n    fib_list = [0, 1]\\n    for i in range(2, n):\\n        fib_list.append(fib_list[i-1] + fib_list[i-2])\\n    return fib_list\\n\\nfirst_20_fibonacci = fibonacci(20)\\nfirst_20_fibonacci',\n",
       "    'outputs': [{'logs': '[0,\\n 1,\\n 1,\\n 2,\\n 3,\\n 5,\\n 8,\\n 13,\\n 21,\\n 34,\\n 55,\\n 89,\\n 144,\\n 233,\\n 377,\\n 610,\\n 987,\\n 1597,\\n 2584,\\n 4181]',\n",
       "      'type': 'logs'}]},\n",
       "   'type': 'code_interpreter'}],\n",
       " 'type': 'tool_calls'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message_creation': {'message_id': 'msg_OqjMe8G4GyLSxDhaZoLSqgWQ'},\n",
       " 'type': 'message_creation'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data:\n",
    "    step_details = step.step_details\n",
    "    print(json.dumps(show_json(step_details), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asst_9AoXVWBxHzWGAb6bYJqyI4tK'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATH_ASSISTANT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_HUCig74tVEzxYoRvyvwwLPq5',\n",
       " 'created_at': 1713293892,\n",
       " 'description': None,\n",
       " 'file_ids': ['file-cY3KNR7ujFVIRlXSEtHhWNRJ'],\n",
       " 'instructions': 'You are professional frontend data visualization developer. Please generate code that answers users questions on data',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}, {'type': 'retrieval'}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'response_format': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\n",
    "        \"data/cities_for_map.csv\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")\n",
    "# Update Assistant\n",
    "# assistant = client.beta.assistants.update(\n",
    "#     MATH_ASSISTANT_ID,\n",
    "#     tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "#     file_ids=[file.id],\n",
    "# )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are professional frontend data visualization developer. Please generate code that answers users questions on data\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    file_ids=[file.id],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: Can you describe the data?\n",
      "assistant: The dataset consists of 4500 entries with 43 columns. The columns include information such as City, Country, Latitude, Longitude, Population, Waste Generation Rate, Waste Components breakdown, Diversion rates, Precipitation, and Methane Capture details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Can you describe the data?\"\n",
    ")\n",
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'all', 'continent': 'all', 'rank': None, 'previousRank': None, 'assetCount': None, 'emissions': {'co2': 43643632890.82764, 'ch4': 401824975.87208563, 'n2o': 7847362.588392702, 'co2e_100yr': 58370910005.58343, 'co2e_20yr': 81507277915.09894}, 'worldEmissions': {'co2': 43643632890.82764, 'ch4': 401824975.87208563, 'n2o': 7847362.588392702, 'co2e_100yr': 58370910005.58343, 'co2e_20yr': 81507277915.09894}, 'emissionsChange': {'co2': 0, 'ch4': 0, 'n2o': 0, 'co2e_100yr': 0, 'co2e_20yr': 0}}\n"
     ]
    }
   ],
   "source": [
    "CLIMATE_TRACE_API_URL='https://api.climatetrace.org/v4/country/emissions?since=2022&to=2022'\n",
    "import requests\n",
    "# Make a GET request to the API\n",
    "response = requests.get(CLIMATE_TRACE_API_URL)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the data from the response\n",
    "    data = response.json()\n",
    "    # Process the data as needed\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            country continent  rank previousRank assetCount     emissions  \\\n",
      "co2            all       all  None         None       None  4.364363e+10   \n",
      "ch4            all       all  None         None       None  4.018250e+08   \n",
      "n2o            all       all  None         None       None  7.847363e+06   \n",
      "co2e_100yr     all       all  None         None       None  5.837091e+10   \n",
      "co2e_20yr      all       all  None         None       None  8.150728e+10   \n",
      "\n",
      "            worldEmissions  emissionsChange  \n",
      "co2           4.364363e+10                0  \n",
      "ch4           4.018250e+08                0  \n",
      "n2o           7.847363e+06                0  \n",
      "co2e_100yr    5.837091e+10                0  \n",
      "co2e_20yr     8.150728e+10                0  >\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_IlfxlF2eIwYoQQ4PZE3U5tBw',\n",
       " 'created_at': 1713299059,\n",
       " 'description': None,\n",
       " 'file_ids': ['file-549SGl3GjP3eYQmWd28ErfWm'],\n",
       " 'instructions': 'You are professional frontend data visualization developer. Please generate code that answers users questions on data',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}, {'type': 'retrieval'}],\n",
       " 'top_p': 1.0,\n",
       " 'temperature': 1.0,\n",
       " 'response_format': 'auto'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the file\n",
    "json_data_file = client.files.create(\n",
    "    file=open(\n",
    "        \"data/cities_for_map.csv\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are professional frontend data visualization developer. Please generate code that answers users questions on data\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    file_ids=[json_data_file.id],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can the assistant handle two csv files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
